# svara-tts-inference

Inference and deployment toolkit for Svara-TTS, an open-source multilingual text-to-speech model for Indic languages â€” includes examples for local GGUF inference, Gradio demo, and production-ready API deployment.

[![ğŸ¤— Hugging Face - svara-tts-v1 Model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Model-black)](https://huggingface.co/kenpath/svara-tts-v1) 
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/15YxFo1DzdQNbFUIZ1HJA4AN4oHqKxGtg)
[![ğŸ¤— Hugging Face - Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-green)](https://huggingface.co/spaces/kenpath/svara-tts)

## Features

- **38 Voice Profiles**: Support for 19 Indian languages with male and female voices
- **Streaming Audio**: Real-time audio generation with low-latency streaming
- **Production Ready**: Docker deployment with vLLM and FastAPI
- **GPU Accelerated**: CUDA-optimized inference with SNAC decoder
- **API Compatible**: ElevenLabs-style REST API for easy integration
- **Zero-Shot Voice Cloning**: Dedicated endpoint to encode custom voices once and re-use via IDs or raw tokens

## Supported Languages

Hindi, Bengali, Marathi, Telugu, Kannada, Bhojpuri, Magahi, Chhattisgarhi, Maithili, Assamese, Bodo, Dogri, Gujarati, Malayalam, Punjabi, Tamil, English (Indian), Nepali, Sanskrit

## Quick Start - API Deployment

Deploy Svara TTS as a production API service with Docker:

```bash
# Clone repository
git clone <repository-url>
cd svara-tts-inference

# Configure (optional)
cp .env.example .env

# Build and start
docker-compose up -d

# Test the API
curl http://localhost:8080/health
curl http://localhost:8080/v1/voices
```

### API Usage

**Get Available Voices:**
```bash
curl http://localhost:8080/v1/voices
```

**Text-to-Speech (preset voice):**
```bash
curl -X POST http://localhost:8080/v1/text-to-speech \
  -H "Content-Type: application/json" \
  -d '{
    "text": "à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤®à¥ˆà¤‚ à¤¸à¥à¤µà¤°à¤¾ à¤Ÿà¥€à¤Ÿà¥€à¤à¤¸ à¤¹à¥‚à¤‚",
    "voice_id": "hi_male",
    "stream": true
  }' \
  --output audio.pcm

# Convert to WAV
ffmpeg -f s16le -ar 24000 -ac 1 -i audio.pcm output.wav
```

**Clone a Voice Once, Then Reuse:**

1. **Encode custom voice tokens**
```bash
curl -X POST http://localhost:8080/v1/voice-clone \
  -F reference_audio=@speaker.wav \
  -F reference_transcript="This is the original sentence that matches the clip" \
  -F return_tokens=true
```
Response:
```json
{
  "voice_id": "6b0a8fd0f2684f1bbb7ca7fd923fb0fd",
  "audio_token_count": 742,
  "sample_rate_hz": 24000,
  "transcript_provided": true,
  "token_preview": [128259, 156939, ...],
  "voice_clone_tokens": [128266, 128342, ...]
}
```
2. **Generate speech with the cloned voice**
```bash
# Option A: reuse server-side cache via ID
curl -X POST http://localhost:8080/v1/text-to-speech \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Use my cloned voice on any new sentence",
    "voice_clone_id": "6b0a8fd0f2684f1bbb7ca7fd923fb0fd",
    "stream": true
  }' --output cloned_voice.pcm

# Option B: send the raw voice_clone_tokens directly
curl -X POST http://localhost:8080/v1/text-to-speech \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Tokens can travel with the request",
    "voice_clone_tokens": [128266, 128342, ...],
    "stream": false
  }' --output cloned_voice.pcm
```

**Python Example:**
```python
import requests

response = requests.post(
    "http://localhost:8080/v1/text-to-speech",
    json={
        "text": "Hello from Svara TTS",
        "voice_id": "en_female",
        "stream": True
    },
    stream=True
)

with open("output.pcm", "wb") as f:
    for chunk in response.iter_content(chunk_size=8192):
        f.write(chunk)
```

See [examples/api_client.py](examples/api_client.py) for more examples.

## API Documentation

### Endpoints

- `GET /health` - Health check
- `GET /v1/voices` - List available voices
- `POST /v1/text-to-speech` - Generate speech from text
- `POST /v1/voice-clone` - Encode reference audio into reusable voice tokens/IDs

### Voice IDs

For `svara-tts-v1`, voice IDs follow the format `{language_code}_{gender}`:
- Hindi: `hi_male`, `hi_female`
- English: `en_male`, `en_female`
- Bengali: `bn_male`, `bn_female`
- [See full list in DEPLOYMENT.md](DEPLOYMENT.md)

For `svara-tts-v2` (coming soon): `rohit`, `priya`, `arjun`, etc.

## Deployment Guide

For detailed deployment instructions, configuration options, and troubleshooting:

**ğŸ“– [Read the Full Deployment Guide â†’](DEPLOYMENT.md)**

Topics covered:
- Prerequisites and hardware requirements
- Docker configuration
- Environment variables
- Production deployment with nginx
- Troubleshooting and monitoring
- Multi-GPU setup

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI       â”‚  Port 8080
â”‚   API Server    â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   vLLM Server   â”‚  Port 8000
â”‚   (LLM Engine)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SNAC Decoder   â”‚  CUDA/GPU
â”‚  (Audio Gen)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Development

### Project Structure

```
svara-tts-inference/
â”œâ”€â”€ api/                    # FastAPI server
â”‚   â””â”€â”€ server.py          # Main API endpoints
â”œâ”€â”€ tts_engine/            # Core TTS engine
â”‚   â”œâ”€â”€ orchestrator.py    # TTS orchestration
â”‚   â”œâ”€â”€ decoder_snac.py    # SNAC decoder
â”‚   â”œâ”€â”€ transports.py      # vLLM transport
â”‚   â”œâ”€â”€ voice_config.py    # Voice profiles
â”‚   â””â”€â”€ utils.py           # Utilities
â”œâ”€â”€ examples/              # Example scripts
â”‚   â””â”€â”€ api_client.py      # API client examples
â”œâ”€â”€ scripts/               # Deployment scripts
â”‚   â””â”€â”€ start.sh          # Container startup
â”œâ”€â”€ Dockerfile             # Docker image
â”œâ”€â”€ docker-compose.yml     # Docker Compose config
â””â”€â”€ requirements.txt       # Python dependencies
```

### Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Start vLLM server separately
python -m vllm.entrypoints.openai.api_server \
  --model kenpath/svara-tts-v1 \
  --port 8000

# Start FastAPI server
cd api
python server.py
```

## Requirements

### Hardware
- GPU: NVIDIA GPU with 16GB+ VRAM (recommended: 24GB+)
- RAM: 16GB+ system RAM
- Storage: 50GB+ free space

### Software
- Docker 20.10+
- Docker Compose 2.0+
- NVIDIA GPU Drivers
- NVIDIA Container Toolkit

## License

See [LICENSE](LICENSE) file for details.

## Citation

If you use Svara TTS in your research, please cite:

```bibtex
@misc{svara-tts-v1,
  title={Svara TTS: Multilingual Text-to-Speech for Indic Languages},
  author={Kenpath},
  year={2024},
  url={https://huggingface.co/kenpath/svara-tts-v1}
}
```

## Links

- ğŸ¤— [Model on Hugging Face](https://huggingface.co/kenpath/svara-tts-v1)
- ğŸš€ [Try Demo on Hugging Face Spaces](https://huggingface.co/spaces/kenpath/svara-tts)
- ğŸ““ [Colab Notebook](https://colab.research.google.com/drive/15YxFo1DzdQNbFUIZ1HJA4AN4oHqKxGtg)
