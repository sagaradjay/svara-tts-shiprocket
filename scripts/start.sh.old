#!/bin/bash
# Startup script for Svara TTS API
# Launches vLLM server and FastAPI server in a single container

set -e

echo "=============================================="
echo "Starting Svara TTS API"
echo "=============================================="

# Configuration
VLLM_MODEL=${VLLM_MODEL:-kenpath/svara-tts-v1}
VLLM_PORT=${VLLM_PORT:-8000}
VLLM_HOST=${VLLM_HOST:-0.0.0.0}
VLLM_GPU_MEMORY_UTILIZATION=${VLLM_GPU_MEMORY_UTILIZATION:-0.9}
VLLM_MAX_MODEL_LEN=${VLLM_MAX_MODEL_LEN:-2048}
VLLM_TENSOR_PARALLEL_SIZE=${VLLM_TENSOR_PARALLEL_SIZE:-1}
VLLM_TRUST_REMOTE_CODE=${VLLM_TRUST_REMOTE_CODE:-true}

API_PORT=${API_PORT:-8080}
API_HOST=${API_HOST:-0.0.0.0}

echo ""
echo "Configuration:"
echo "  vLLM Model: $VLLM_MODEL"
echo "  vLLM Port: $VLLM_PORT"
echo "  vLLM GPU Memory: $VLLM_GPU_MEMORY_UTILIZATION"
echo "  vLLM Max Model Length: $VLLM_MAX_MODEL_LEN"
echo "  API Port: $API_PORT"
echo ""

# Function to check if vLLM is ready
wait_for_vllm() {
    echo "Waiting for vLLM server to be ready..."
    local max_attempts=60
    local attempt=0
    
    while [ $attempt -lt $max_attempts ]; do
        if curl -s http://localhost:${VLLM_PORT}/health > /dev/null 2>&1; then
            echo "✓ vLLM server is ready!"
            return 0
        fi
        
        attempt=$((attempt + 1))
        echo "  Attempt $attempt/$max_attempts..."
        sleep 5
    done
    
    echo "✗ Error: vLLM server did not become ready in time"
    return 1
}

# Function to handle shutdown
cleanup() {
    echo ""
    echo "=============================================="
    echo "Shutting down Svara TTS API..."
    echo "=============================================="
    
    # Kill vLLM server
    if [ ! -z "$VLLM_PID" ]; then
        echo "Stopping vLLM server (PID: $VLLM_PID)..."
        kill $VLLM_PID 2>/dev/null || true
        wait $VLLM_PID 2>/dev/null || true
    fi
    
    # Kill FastAPI server
    if [ ! -z "$API_PID" ]; then
        echo "Stopping FastAPI server (PID: $API_PID)..."
        kill $API_PID 2>/dev/null || true
        wait $API_PID 2>/dev/null || true
    fi
    
    echo "✓ Shutdown complete"
    exit 0
}

# Set up signal handlers
trap cleanup SIGTERM SIGINT SIGQUIT

# ============================================================================
# Step 1: Start vLLM server
# ============================================================================

echo "=============================================="
echo "Step 1: Starting vLLM server"
echo "=============================================="

python3 -m vllm.entrypoints.openai.api_server \
    --model "$VLLM_MODEL" \
    --host "$VLLM_HOST" \
    --port "$VLLM_PORT" \
    --gpu-memory-utilization "$VLLM_GPU_MEMORY_UTILIZATION" \
    --max-model-len "$VLLM_MAX_MODEL_LEN" \
    --tensor-parallel-size "$VLLM_TENSOR_PARALLEL_SIZE" \
    --trust-remote-code \
    --dtype auto \
    --enable-auto-tool-choice \
    --tool-call-parser hermes \
    > /tmp/vllm.log 2>&1 &

VLLM_PID=$!
echo "✓ vLLM server started (PID: $VLLM_PID)"
echo "  Logs: /tmp/vllm.log"

# Wait for vLLM to be ready
if ! wait_for_vllm; then
    echo "vLLM startup logs:"
    tail -n 50 /tmp/vllm.log
    exit 1
fi

# ============================================================================
# Step 2: Start FastAPI server
# ============================================================================

echo ""
echo "=============================================="
echo "Step 2: Starting FastAPI server"
echo "=============================================="

cd /app/api

python3 -m uvicorn server:app \
    --host "$API_HOST" \
    --port "$API_PORT" \
    --log-level info \
    > /tmp/api.log 2>&1 &

API_PID=$!
echo "✓ FastAPI server started (PID: $API_PID)"
echo "  Logs: /tmp/api.log"

# Wait a moment for FastAPI to start
sleep 5

# Check if FastAPI is running
if ! curl -s http://localhost:${API_PORT}/health > /dev/null 2>&1; then
    echo "⚠ Warning: FastAPI server may not be ready yet"
    echo "FastAPI startup logs:"
    tail -n 20 /tmp/api.log
fi

# ============================================================================
# Ready!
# ============================================================================

echo ""
echo "=============================================="
echo "✓ Svara TTS API is ready!"
echo "=============================================="
echo ""
echo "Endpoints:"
echo "  Health Check:     http://localhost:${API_PORT}/health"
echo "  Get Voices:       http://localhost:${API_PORT}/v1/voices"
echo "  Text-to-Speech:   http://localhost:${API_PORT}/v1/text-to-speech"
echo ""
echo "vLLM Server:"
echo "  OpenAI API:       http://localhost:${VLLM_PORT}/v1"
echo ""
echo "Press Ctrl+C to stop"
echo "=============================================="
echo ""

# Wait for either process to exit
wait $VLLM_PID $API_PID

# If we get here, one of the processes died
echo "✗ One of the services has stopped unexpectedly"
cleanup

